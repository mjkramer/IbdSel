* New action items
** TODO Why are we getting "MuonAlg is exhausted" for some files in P19A?
EH3 day 2323, see /global/homes/m/mkramer/mywork/ThesisAnalysis/IbdSel/log/stage2/p19a@nominal/slurm_knl-37251880_3.out
See also StrongAmC day 272, 31804 127: /global/homes/m/mkramer/mywork/ThesisAnalysis/IbdSel/log/stage2/StrongAmC@nominal/slurm_knl-38721779_1.out
** TODO Make h_ncap bins half as small. Consider using fine_integral. Currently our binning is too coarse.
** TODO Switch from relative to absolute delayed efficiencies in fit_prep.
** TODO Redo muon veto studies after fix in SinglesCalc::singlesCount (eMu -> eMuSingles)
* Action items
BB: screen on cori06
** TODO Benchmark 500 files around n=68
** TODO Add HistGen
Need to fake rebinning?
** TODO Write CLI driver for TextGen/HistGen
** TODO Test/debug
** TODO Figure out why li9calc is off
** TODO Produce and check yolo inputs
** TODO Run fitter chain
** TODO Fix IbdSelector histogram binning (240 bins)
* Things to do
** DONE Fix accidentals/DMC calc and compare 1+ daily value to LBNL [3/4]
CLOSED: [2020-01-15 Wed 23:30]
- [X] Ensure singles sel/calc use consistent muon veto
- [X] Apply stashed corrections to calc
Still not fully consistent with technote, see (1.10) [FIXED]
- [X] Process one day in each hall, compare to LBNL
Should check more extensively?
- [ ] Fix acc rate error? [WONTFIX]
** DONE Implement Li9 rate calculation [1/2]
CLOSED: [2020-01-15 Wed 23:30]
- [X] Write code
- [ ] Test code
** TODO Check implementation of other backgrounds
In fit_prep? c.f. 
** DONE Add accidentals spectrum?
CLOSED: [2020-01-16 Thu 12:17]
Already have the singles histograms, dur.
** TODO Run checks of daily everything vs LBNL
** DONE Update job script for stage1
CLOSED: [2020-01-28 Tue 17:03]
** DONE Update stage1 merge job?
CLOSED: [2020-01-28 Tue 17:03]
** TODO Write/test job script to do stage2 + merge + fit
** DONE Run stage1 (+ merge?) on P17B
CLOSED: [2020-01-28 Tue 17:03]
** TODO Do one fit, to test
** TODO Do another N fits

** Refactorings?
- Add a <TagT> parameter to Node?
* ROOT stuff
** Usage with PyROOT
...(for, e.g., using test_candidates.py)
With current janky environment, do not compile C++ from within PyROOT! The "wrong" dynamic libs get linked in. Compile code from "plain" ROOT, then load the .so from PyROOT. This applies to things like test/FileFinder.cc too.

** PyROOT bugs
- [[https://sft.its.cern.ch/jira/browse/ROOT-7240][Scoped enums]] (also [[https://root-forum.cern.ch/t/enumerator-classes-available-in-root-using-linkdef/30728][roottalk]])

** Compiling, linking, dictionaries
*** Magic environment variables
- CPLUS_INCLUDE_PATH
- ROOT_INCLUDE_PATH
*** Magic macros
- R__LOAD_LIBRARY
- R__ADD_INCLUDE_PATH
- R__ADD_LIBRARY_PATH
*** References
- [[https://root-forum.cern.ch/t/shared-libraries-in-root-6-06-04/22270]]
- https://root-forum.cern.ch/t/gsystem-load-vs-r-load-library-with-aclic/29685
- https://root-forum.cern.ch/t/makefile-with-gsl-libraries/32024
- https://root-forum.cern.ch/t/symbol-gsl-sf-bessel-j0-unresolved-while-linking-cling-interface-function/31577
- https://root-forum.cern.ch/t/undefined-symbols-for-architecture-x86-64/33922
- https://root-forum.cern.ch/t/weird-error-output-from-cling/19410
- https://root-forum.cern.ch/t/rootmap-generation-with-rootcling-v6-00-00/17758
- https://root-forum.cern.ch/t/how-to-load-an-shared-object-that-also-depends-on-clang-llvm-in-cling/38054
- https://sft.its.cern.ch/jira/browse/ROOT-6325
** jupyter console
*** Wrong sys.path?
https://github.com/jupyter/notebook/issues/3311
If necessary go to ~/.local/share/jupyter/kernels and create a new one pointing to the appropriate Python. It can be used with e.g. =jupyter console --kernel=mykernel=.
*** Needed patches
In ROOT.py, the inputhook-based event loop won't work, so use the old threading-based approach instead. Also, JupyROOT messes up tab-completion so don't import it. Patch ROOT.py like:
#+begin_src diff
--- ROOT.py.bak	2019-06-25 01:52:11.000000000 -0700
+++ ROOT.py	2020-03-07 20:48:29.853977716 -0800
@@ -767,7 +767,9 @@
     # use either the input hook or thread to send events to GUIs
       if self.PyConfig.StartGuiThread and \
             not ( self.keeppolling or _root.gROOT.IsBatch() ):
-         if _is_ipython and 'IPython' in sys.modules and sys.modules['IPython'].version_info[0] >= 5 :
+         if (not os.getenv('NO_JUPYROOT') and
+             _is_ipython and 'IPython' in sys.modules and sys.modules['IPython'].version_info[0] >= 5):
+
             from IPython.terminal import pt_inputhooks
             import time
             def _inputhook(context):
@@ -830,7 +832,7 @@
 if _is_ipython:
    from IPython import get_ipython
    ip = get_ipython()
-   if hasattr(ip,"kernel"):
+   if hasattr(ip,"kernel") and not os.getenv('NO_JUPYROOT'):
       import JupyROOT
       import JsMVA

#+end_src
and set the NO_JUPYROOT env var when launching console/kernel.
** ibdsel1 conda env
conda create --name ibdsel1 --file $IBDSEL_HOME/doc/conda/ibdsel1.txt
# https://github.com/ContinuumIO/anaconda-issues/issues/11152
# https://github.com/conda/conda/issues/6030
# had to install local python in conda env, remove the compat ld
# before installing root-numpy./pandas

* Multiple input files?
Problem is in stage1: AdSaver needs to be able to know when the input file has changed so that it can update the run/file in the output tree. SyncReader needs to be able to notify downstream algs when the input file changes to the next one in the chain. Stage2 is fine as-is.

* Running the chain
** Environment setup
Start with a fresh login. Then
#+begin_src bash
source bash/job_env.inc.sh
#+end_src
Now you are in the same environment that jobs will run in. Includes Python 3.7, ROOT 6.18, Pandas. It's OK to submit jobs from a different environment, as we whitelist the env vars that get exported to the job. However, for doing things interactively, it's a good idea to use the job environment.

** Testing stage1
*** Generating smaller input
#+begin_src bash
# First 10 files:
scripts/prep_stage1.sh -f "head -n -10" $tag

# Random 10 files:
scripts/prep_stage1.sh -f "shuf -n 10" $tag
#+end_src

*** Running interactively (one process)
#+begin_src bash
newenv
bash/stage1_job.sh $tag
#+end_src

*** Checking sbatch command
Set IBDSEL_DRYRUN=1 when running submit_stage1_foo.sh

*** Testing on batch
#+begin_src bash
# $sys is either knl or hsw
tests/submit_stage1_debug_$sys.sh $tag
#+end_src

*** Cleaning up
eval `scripts/clear.sh stage1 $tag`

** Submitting stage1
Do everything from ibd_prod directory, within a fresh shell environment

*** Safety check
Make sure stage1_main.cc.so is the newest file in selector/, and be sure that you didn't compile it from PyROOT

*** Prepare dirs
#+begin_src bash
scripts/prep_stage1.sh $tag
#+end_src

*** Submit
#+begin_src bash
scripts/submit_stage1_$sys.sh $tag $njob
#+end_src

*** Iterating to completion (not tested)
If no jobs are running:
#+begin_src bash
scripts/filter_done.sh stage1 $tag
#+end_src

If N jobs are running, calculate pending = N * chunksize, then
#+begin_src bash
scripts/filter_done.sh -p $pending stage1 $tag
#+end_src
This assumes that all running jobs are processing items drawn from the current version of input.stage1.txt. If that file was updated after a job was launched, and that job has yet to pull any items off the new list, then the above method won't work right. Some files will be omitted even though nobody is processing them, and some in-progress files will be include. If in doubt, just wait for jobs to finish.

*** End result
560k stage1 files in ../../data/stage1_fbf/$tag/EH1/0021200/0021221 etc.

** Merging stage1
*** Prepare input
#+begin_src bash
scripts/prep_merge1.sh $tag
#+end_src

*** Running the merge
#+begin_src bash
scripts/run_merge1.sh $tag $nproc
#+end_src
It's fine to add processes to a running merge. With 8 processes spread between two Cori login nodes, P17B took 4 hours.

*** Iterating (not tested)
#+begin_src bash
scripts/filter_done.sh merge1 $tag
#+end_src

*** Checking
Grep the logs for CRAPPY. Try to redo stage1 for those files. Those that cannot be resolved should be tagged as bad. (P17B good run list v3 should be 100% viable.)

*** Cleanup
Delete the fbf files

*** Preservation
Copy the dbd files to CFS

*** End result
6k daily stage1 files in ../../data/stage1_dbd/$tag/EH1 etc.

** Stage2 testing
*** DONE Run stage2_job.sh interactively, no IBDSEL_CONFIGDIR
CLOSED: [2020-01-31 Fri 21:44]
*** DONE Run stage2_job.sh interactively, set IBDSEL_CONFIGDIR to ../misc/configs and use a "config.altered.txt" in there
CLOSED: [2020-01-31 Fri 23:17]
*** DONE Test in debug QOS
CLOSED: [2020-02-01 Sat 01:41]
*** DONE Using performance numbers, draft submit_stage2_${sys}_debug.sh
CLOSED: [2020-03-07 Sat 21:16]
*** DONE Run some benchmarks to determine ideal performance params
CLOSED: [2020-03-07 Sat 21:16]
*** DONE Update submit_XXX performance params
CLOSED: [2020-03-07 Sat 21:16]
*** TODO Investigate "MuonAlg is behind!" etc. [1/2]
- [X] Find culprit
:notes:
Seems to be when the next file is missing.
Or end of a run.
:END:
- [ ] Add (optional) shower muon veto before/after gaps?
*** TODO Investigate discrepancy in number of days between halls
*** DONE Submit one full job
CLOSED: [2020-03-07 Sat 21:18]
** Creating the burst buffer (for bulk stage2)
Use https://my.nersc.gov/queuewaittimes.php to choose between Haswell and KNL (debug queue).
#+begin_src bash
sbatch -C knl slurm/create_BB.sl.sh
#+end_src
** Filling the burst buffer
Apparently half an hour ain't enough. With a cold cache, half an hour copied all of EH1 and most of EH2. Subsequent full copy took 25 minutes.
#+begin_src bash
# salloc -q debug -C knl -t 00:30:00 --bbf=slurm/bbf.conf
salloc -q interactive -C haswell -t 02:00:00 --bbf=slurm/bbf.conf
mkdir -p $DW_PERSISTENT_STRIPED_dyb_ibdsel/stage1_dbd
time cp -RL ../../data/stage1_dbd/2020_01_26 $DW_PERSISTENT_STRIPED_dyb_ibdsel/stage1_dbd
#+end_src
** Submitting stage2
*** Preparing
#+begin_src bash
# if unset, uses ../static/configs (which just has nominal cuts)
export IBDSEL_CONFIGDIR=some_dir
# use -f to produce a short list for testing purposes, like prep_stage1
scripts/prep_stage2.sh $tag $configname
#+end_src

If, for testing purposes, you'd like to use the nominal config under a different name, pass the -c option to prep_stage2.sh. E.g., for a quick test:
#+begin_src bash
scripts/prep_stage2.sh -f 'shuf -n 10' -c $tag test10
#+end_src

*** Clearing
#+begin_src bash
eval $(scripts/clear.sh stage2 $tag $configname)
#+end_src
See also reset.sh

*** Testing interactively
#+begin_src bash
bash/stage2_job.sh $tag $configname
#+end_src

*** Submitting
Use IBDSEL_DRYRUN=1 to preview the sbatch command without submitting
#+begin_src bash
scripts/submit_stage2_knl.sh $tag $configname $njob
#+end_src

*** Iterating

*** End result
6k daily stage2 files 
** Merging stage2
Expect 7 minutes.
#+begin_src bash
python/merge2_worker.py $tag $configname
#+end_src
** Deleting the burst buffer
If we won't be running stage2 for a while.
#+begin_src bash
sbatch -C knl slurm/destroy_BB.sl.sh
#+end_src
